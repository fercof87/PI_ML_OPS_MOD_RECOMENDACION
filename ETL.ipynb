{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRERIAS GENERALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from Funciones.json_func import *\n",
    "from Funciones.textblob import *\n",
    "from Funciones.dates import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRATAMIENTO DE STEAM GAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos las columnas relevantes para el MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_output_steam_json = ['item_id', 'genres', 'release_date', 'price', 'developer'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura del Json.Gz de STEAM GAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previo a las Creacion de Particiones\n",
    "#df_output_steam_json_entero = leerJsonGz(\"Datos/\",\"steam_games.json.gz\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura y union de particiones\n",
    "df_output_steam_json = leerJsonGzPart(\"Datos/Particiones/\",\"steam_games.json.gz\",0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se comprobo que funciono el particionamiento de este archivo\n",
    "#print(\"Shape lectura completa    : \", df_output_steam_json_entero.shape)\n",
    "#print(\"Shape lectura particionada: \", df_output_steam_json.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombra la columna \"id\" a \"item_id\"\n",
    "df_output_steam_json.rename(columns={\"id\": \"item_id\"}, inplace=True)\n",
    "df_output_steam_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json[df_output_steam_json['item_id'] == '10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VALIDAMOS LA ESTRUCTURA ITEMS (anidada) DEL ARCHIVO STEAM GAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se detecto que si viene informado ITEMs el resto de los datos es nulo.\n",
    "\n",
    "Ademas, esa informacion ya la tenemos en USER ITEMs. Asi que sera descartada por redundancia de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json[df_output_steam_json[\"items\"].notna()][['item_id', 'genres', 'release_date', 'price', 'developer', 'items']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_output_steam_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nos quedamos con las columnas necesarias para los EndPoints\n",
    "df_output_steam_json = df_output_steam_json[cols_output_steam_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json[cols_output_steam_json].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELIMINAMOS REGISTROS SIN INFORMACION, GENERADOS POR LA ESTRUCTURA ITEMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solo elimina las filas donde todos sus campos o columnas sean Nulas.\n",
    "df_output_steam_json = df_output_steam_json.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVAMOS LA PRESENCIA DE NULOS EN LAS COLUMNAS SELECCIONADAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRATAMIENTO DE NULOS CAMPO A CAMPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ITEM-ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observamos la cantidad de registros nulos de ITEM-ID\n",
    "df_output_steam_json[df_output_steam_json[\"item_id\"].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observamos los registros nulos de ITEM-ID\n",
    "df_output_steam_json[df_output_steam_json[\"item_id\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a la eliminacion de los registros sin Item_Id ya que no hay forma de imputarlo o reconstruirlo con los datos que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantidad de Registros previo a la eliminacion\n",
    "df_output_steam_json.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina las filas donde \"item_id\" sea nulo\n",
    "df_output_steam_json = df_output_steam_json.dropna(subset=[\"item_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantidad de Registros luego de la eliminacion\n",
    "df_output_steam_json.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos la columna a Entero\n",
    "df_output_steam_json['item_id'] = df_output_steam_json['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENRES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VALIDO CUANTOS GENROS DIFERENTES TENGO PREVIO A CUALQUIER MODIFICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierto en string\n",
    "# Si no es lista se pasa directo a string\n",
    "#Si es lista, se conveierte a cadena, separando los elementos (generos) por coma.\n",
    "genres_str = df_output_steam_json[\"genres\"].apply(lambda x: ', '.join(map(str, x)) if isinstance(x, list) else str(x))\n",
    "\n",
    "# Dividir la columna 'genres' en géneros individuales y crear un conjunto de géneros únicos\n",
    "unique_genres_set = set(genres_str.str.split(',').explode().str.strip())\n",
    "\n",
    "# Convertir el conjunto de géneros únicos en una lista\n",
    "unique_genres_list = list(unique_genres_set)\n",
    "\n",
    "# Mostrar la lista de géneros únicos\n",
    "print(unique_genres_list)\n",
    "print(len(unique_genres_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observamos la cantidad de registros nulos en el campo GENRES\n",
    "df_output_steam_json[df_output_steam_json[\"genres\"].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json[df_output_steam_json[\"genres\"].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que es muy dificil obtener un resultado CONFIABLE al tratar de inferir los generos con el resto de la informacion disponible, se ha optado por hacer un ETIQUETADO especial a esos registros con generos nulos.\n",
    "\n",
    "Se procedera a imputar [\"Desconocido] a todos esos casos con el objetivo de no perder informacion relevante como ser: precios, fechas, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminamos los elementos o generos 'Free To Play' y 'Early Access' ya que condiseramos no ser un genero.\n",
    "df_output_steam_json['genres'] = df_output_steam_json['genres'].apply(lambda x: [genre for genre in x if isinstance(x, list) and genre != 'Free to Play'] if isinstance(x, list) else x)\n",
    "df_output_steam_json['genres'] = df_output_steam_json['genres'].apply(lambda x: [genre for genre in x if isinstance(x, list) and genre != 'Early Access'] if isinstance(x, list) else x)\n",
    "\n",
    "#Si solamente tenia ese genero, me va a quedar una lista vacia, en esos casos imputo Desconocido\n",
    "df_output_steam_json['genres'] = df_output_steam_json['genres'].apply(lambda x: ['Desconocido'] if (isinstance(x, list) and (len(x) == 0 or (len(x) == 1 and x[0] == ''))) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierto en string\n",
    "# Si no es lista se pasa directo a string\n",
    "#Si es lista, se conveierte a cadena, separando los elementos (generos) por coma.\n",
    "genres_str = df_output_steam_json[\"genres\"].apply(lambda x: ', '.join(map(str, x)) if isinstance(x, list) else str(x))\n",
    "\n",
    "# Dividir la columna 'genres' en géneros individuales y crear un conjunto de géneros únicos\n",
    "unique_genres_set = set(genres_str.str.split(',').explode().str.strip())\n",
    "\n",
    "# Convertir el conjunto de géneros únicos en una lista\n",
    "unique_genres_list = list(unique_genres_set)\n",
    "\n",
    "# Mostrar la lista de géneros únicos\n",
    "print(unique_genres_list)\n",
    "print(len(unique_genres_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformo la columna de genres en string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica el contenido de GENRES\n",
    "# Si no es lista se pasa directo a string\n",
    "#Si es lista, se conveierte a cadena, separando los elementos (generos) por coma.\n",
    "df_output_steam_json[\"genres\"] = df_output_steam_json[\"genres\"].apply(lambda x: ', '.join(map(str, x)) if isinstance(x, list) else str(x)).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica y asigna \"Desconocido\" a registros nulos y vacios en la columna \"genres\"\n",
    "df_output_steam_json['genres'] = df_output_steam_json['genres'].apply(lambda x: \"Desconocido\" if x == 'nan' else x)\n",
    "df_output_steam_json['genres'] = df_output_steam_json['genres'].apply(lambda x: \"Desconocido\" if x == '' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observamos los registros nulos tras la imputacion\n",
    "df_output_steam_json[df_output_steam_json[\"genres\"].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json[df_output_steam_json['genres'] == ''].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sustituir la subcadena 'Design &amp; ' por ''\n",
    "df_output_steam_json['genres'] = df_output_steam_json['genres'].str.replace('Design &amp; ', '')\n",
    "df_output_steam_json['genres'] = df_output_steam_json['genres'].str.replace('Animation &amp; ', '')\n",
    "df_output_steam_json['genres'] = df_output_steam_json['genres'].str.rstrip(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json[df_output_steam_json['genres'] == ''].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RELEASE_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observamos los registros nulos\n",
    "df_output_steam_json[df_output_steam_json[\"release_date\"].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que es muy dificil obtener un resultado CONFIABLE al tratar de inferir las FECHAS de LANZAMIENTO con el resto de la informacion disponible, se ha optado por imputar un valor especial a esos registros con fechas nulas.\n",
    "\n",
    "Se procedera a imputar 1900-01-01 a todos esos casos con el objetivo de no perder informacion relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previo a dicha imputacion comprobamos que esa fecha NO se este utilizando\n",
    "df_output_steam_json[df_output_steam_json[\"release_date\"].str.strip() == \"1900-01-01\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizo un registro para ver como imputa la fecha default\n",
    "df_output_steam_json[df_output_steam_json[\"release_date\"].isna()].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asigna '1900-01-01' a los registros nulos en la columna \"release_date\"\n",
    "df_output_steam_json[\"release_date\"].fillna(pd.to_datetime(DEFAULT_DATE).date().strftime(\"%Y-%m-%d\"), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observamos los registros nulos tras la imputacion\n",
    "df_output_steam_json[df_output_steam_json[\"release_date\"].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizo el registro anterior post imputacion de DEFAULT DATE\n",
    "df_output_steam_json[df_output_steam_json[\"item_id\"] == 773570]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos verificar la diversidad de posibilidades que nos podemos encontrar ya que manualmente hemos observado muchos tipos de fechas. \n",
    "\n",
    "Vamos a Realizar una separacion de los datos que no estan bajo el formato YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Casteamos a String\n",
    "df_output_steam_json['release_date'] = df_output_steam_json['release_date'].astype(str)\n",
    "\n",
    "# Aplica la función de conversión a la columna 'release_date'\n",
    "df_output_steam_json['converted_release_date'] = df_output_steam_json['release_date'].apply(convertReleaseFuzzy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VALIDAMOS QUE TODAS LAS FECHAS SE HAYAN TRATADO CORRECTAMENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra los registros que no se pudieron convertir\n",
    "failed_conversion_df = df_output_steam_json[df_output_steam_json['converted_release_date'].isna()]\n",
    "\n",
    "# Muestra el nuevo DataFrame con el conteo de valores\n",
    "print(\"Cantidad de Fechas que no pudieron ser tratadas: \", failed_conversion_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json[df_output_steam_json['release_date'] == pd.to_datetime(DEFAULT_DATE).date().strftime(\"%Y-%m-%d\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json[(df_output_steam_json['converted_release_date'] == DEFAULT_DATE) & (df_output_steam_json['release_date'] != DEFAULT_DATE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos una columna a la otra\n",
    "df_output_steam_json['release_date'] = df_output_steam_json['converted_release_date']\n",
    "#eliminamos Columna intermedia \n",
    "df_output_steam_json.drop(columns=['converted_release_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERAMOS COLUMNA YEAR que nos sera util para los endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer el año de la columna 'release_date'\n",
    "df_output_steam_json['year'] = df_output_steam_json['release_date'].str[:4]\n",
    "\n",
    "# Convertir la columna 'year' a tipo numérico\n",
    "df_output_steam_json['year'] = pd.to_numeric(df_output_steam_json['year'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertimos a String\n",
    "df_output_steam_json['release_date'] = df_output_steam_json['release_date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte la columna 'price' a numérica, y los valores no válidos se convierten en NaN\n",
    "df_output_steam_json['price_convertidos'] = pd.to_numeric(df_output_steam_json['price'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json[df_output_steam_json['item_id'] == 761140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vemos que price tenian aquellos que no hemos podido convertir para ver como tratarlos\n",
    "df_output_steam_json[df_output_steam_json['price_convertidos'].isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nos quedamos con los valores unicos de esos Prices extraños\n",
    "df_output_steam_json[df_output_steam_json['price_convertidos'].isna()]['price'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos las transformaciones de esos casos extraños"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Casos con Starting at $\n",
    "df_output_steam_json['price'] = df_output_steam_json['price'].apply(lambda x: x.replace('Starting at $', '') if isinstance(x, str) and 'Starting at $' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modificamos los FREE\n",
    "# Utiliza str.contains() para identificar registros que contienen \"free\" (sin importar mayúsculas o minúsculas)\n",
    "# Modifica los registros que cumplen con la condición a 0.0\n",
    "df_output_steam_json.loc[df_output_steam_json['price'].str.contains('free', case=False, na=False), 'price'] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a aplicar la conversion..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte la columna 'price' a numérica, y los valores no válidos se convierten en NaN\n",
    "df_output_steam_json['price_convertidos'] = pd.to_numeric(df_output_steam_json['price'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nos quedamos con los valores unicos de esos Prices extraños\n",
    "df_output_steam_json[df_output_steam_json['price_convertidos'].isna()]['price'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASUMIMOS COMO AUSENCIA DE INFORMACION PARA ESOS CASOS, CON LO CUAL QUEDARAN CON NaN luego de la transformacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json['price'] = df_output_steam_json['price_convertidos']\n",
    "df_output_steam_json.drop('price_convertidos', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json[df_output_steam_json['item_id'] == 761140]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEVELOPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizamos algunos registros con DEVELOPER nulo\n",
    "df_output_steam_json[df_output_steam_json['developer'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantidad total de nulos en columna DEVELOPER previo a la imputacion\n",
    "df_output_steam_json[df_output_steam_json['developer'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica y asigna \"Desconocido\" a registros nulos en la columna \"developer\"\n",
    "df_output_steam_json['developer'] = df_output_steam_json['developer'].apply(lambda x: \"Desconocido\" if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantidad total de nulos en columna DEVELOPER luego de la imputacion\n",
    "df_output_steam_json[df_output_steam_json['developer'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizamos algunos registros\n",
    "df_output_steam_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantidad de Developers diferentes\n",
    "df_output_steam_json['developer'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json['developer'] = df_output_steam_json['developer'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantidad de Developers diferentes\n",
    "df_output_steam_json['developer'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNA VEZ FINALIZADAS TODAS LAS TRANSFORMACIONES VOLVEMOS A ELIMINAR DUPLICADOS POR LAS DUDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos cantidad de Registros antes de la eliminacion\n",
    "df_output_steam_json.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina registros duplicados en el DataFrame\n",
    "df_output_steam_json.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos cantidad de Registros despues de la eliminacion\n",
    "df_output_steam_json.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reseteamos indices\n",
    "df_output_steam_json.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos a string\n",
    "df_output_steam_json['developer'] = df_output_steam_json['developer'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USER REVIEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos las columnas relevantes para el MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_user_reviews = [\"user_id\", \"posted\", \"item_id\", \"recommend\", \"review\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LECTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura previa al particionamiento\n",
    "#df_user_reviews_entero = leerJsonGz(\"Datos/\", \"user_reviews.json.gz\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura y union de particiones\n",
    "df_user_reviews = leerJsonGzPart(\"Datos/Particiones/\",\"user_reviews.json.gz\",0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se comprobo que el particionamiento ha funcionado\n",
    "#print(\"Shape Lectura Completa    : \",df_user_reviews_entero.shape)\n",
    "#print(\"Shape Lectura Particionada: \",df_user_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizamos DF\n",
    "df_user_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESANIDAMOS\n",
    "\n",
    "Invoca a la funcion que desanida los json. En este caso, abrira en tantas columnas como claves tengan los diccionarios que estan dentro de la estructura REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de Registros sin desanidar: \", df_user_reviews.shape[0])\n",
    "print(\"Cantidad de Columnas  sin desanidar: \", df_user_reviews.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews = desanidarJson(df_user_reviews, 'reviews')\n",
    "df_user_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de Registros luego de desanidar: \", df_user_reviews.shape[0])\n",
    "print(\"Cantidad de Columnas  luego de desanidar: \", df_user_reviews.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Me quedo con las columnas Relevantes para el MVP\n",
    "df_user_reviews = df_user_reviews[cols_user_reviews]\n",
    "df_user_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELIMINO REGISTROS QUE NO ME SIRVEN\n",
    "\n",
    "- Cuando review y recommend estan sin informacion, ya que no me aportan ninguna informacion esos registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews = df_user_reviews.dropna(subset=['recommend', 'review'], how='all')\n",
    "df_user_reviews.reset_index(drop=True, inplace=True)\n",
    "df_user_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> Podemos ver que no hay mas valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSFORMACIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POSTED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fecha Viene sin año en algunos casos y ademas esta en un formato poco util. vamos a proceder a llevarla a YYYY-MM-DD al igual que lo hicimos con RELEASE_DATE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quito Espacios\n",
    "df_user_reviews['posted'] = df_user_reviews['posted'].str.strip()\n",
    "#Quitamos palabra 'Posted' y el '.' final.\n",
    "df_user_reviews['posted'] = df_user_reviews['posted'].str.replace('Posted ', '').str.replace('.', '')\n",
    "#No hay nulos, pero si los hubiera completariamos con una fecha default\n",
    "df_user_reviews['posted'].fillna(DEFAULT_DATE_LONG, inplace=True)\n",
    "# Realiza el cambio de formato de la FECHA hacia YYYY-MM-DD\n",
    "df_user_reviews['posted_new'] = df_user_reviews['posted'].apply(convertPosted)\n",
    "df_user_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmamos nuevamente que no hay posteos sin fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de Fechas Default en USER REVIEWs: \", df_user_reviews[df_user_reviews[\"posted\"] == \"1900-01-01\"].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews[\"posted\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veo cuantas fechas hay con año 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews[df_user_reviews['posted_new'].str.contains('1900')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pudo ver que las fechas, luego de aplicar el drop de registros sin recommend y sin revew, vienen siempre informadas. Pero hay un defecto. Hay fechas sin año, es decir, viene solo mes y dia.\n",
    "\n",
    "==> Imputamos como año de Posteo el correspondiente a La fecha de Lanzamiento del Contenido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos series booleanas para buscar las fechas con año 1900 pero que no tengan dia y mes 01.\n",
    "#Si tiene año 1900 y no es 01 el dia y mes, quiere decir que es una feha que vino informada SIN año. En ese caso imputamos año de lantamiento si es que lo tenemos. Sino DEFAULT_DATE.\n",
    "es_1900  = df_user_reviews['posted_new'].str[:4] == \"1900\"\n",
    "no_es_01 = df_user_reviews['posted_new'].str[4:9] != \"01-01\"\n",
    "# Combina las condiciones\n",
    "es_1900_y_no_es_01 = es_1900 & no_es_01\n",
    "# Filtra el DataFrame para obtener las filas que cumplen con las condiciones\n",
    "df_user_reviews[es_1900_y_no_es_01].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comprobacion de un caso puntual con DEFAULT\n",
    "df_user_reviews[(df_user_reviews['item_id'] == '248820') & (df_user_reviews['user_id'] == 'evcentric')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos cuantos casos de estos tenemos en nuestro data frame\n",
    "df_user_reviews[es_1900_y_no_es_01].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reseteamos indices\n",
    "df_user_reviews.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews_filtrado = df_user_reviews[es_1900_y_no_es_01]\n",
    "\n",
    "# Para cada registro en los registros filtrados\n",
    "for indice, fila in df_user_reviews_filtrado.iterrows():\n",
    "    item_id = fila['item_id']  # Obtiene el valor de 'item_id' de df_user_reviews\n",
    "    \n",
    "    # Busca las coincidencias para item_id en df_output_steam_json\n",
    "    coincidencias = df_output_steam_json[df_output_steam_json['item_id'] == item_id]\n",
    "    \n",
    "    # Verifica si se encontraron coincidencias antes de intentar acceder al valor\n",
    "    if not coincidencias.empty:\n",
    "        # Obtén el primer valor de 'release_date' en las coincidencias\n",
    "        anio_release = coincidencias['release_date'].str[:4].values[0]\n",
    "        # Actualiza solo los primeros 4 caracteres de 'posted_new' en df_user_reviews\n",
    "        df_user_reviews.at[indice, 'posted_new'] = anio_release + df_user_reviews.at[indice, 'posted_new'][4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews[es_1900_y_no_es_01].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comprobacion de un caso puntual con DEFAULT\n",
    "df_output_steam_json[df_output_steam_json['item_id'] == 218620]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora solo aplicamos DEFAULT_DATE para aquellas fechas de posteo que aun tengan año 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra el DataFrame para obtener las filas que cumplen con las condiciones\n",
    "es_1900  = df_user_reviews['posted_new'].str[:4] == \"1900\"\n",
    "df_user_reviews[es_1900].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validacion de caso puntual item_id = 271290\n",
    "#Como no se encontro en el df, no actualizo el año\n",
    "df_output_steam_json[df_output_steam_json['item_id'] == 271290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputamos DEFAULT_DATE en estos casos\n",
    "\n",
    "# Filtro para identificar los registros que cumplen con es_1900\n",
    "registros_es_1900 = df_user_reviews[es_1900]\n",
    "\n",
    "# Modificar la columna 'posted_new' en los registros filtrados\n",
    "registros_es_1900.loc[:, 'posted_new'] = DEFAULT_DATE\n",
    "\n",
    "# Actualizar df_user_reviews con los cambios\n",
    "df_user_reviews.update(registros_es_1900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews[es_1900].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reemplazamos la columna de posted y eliminamos la intermedia\n",
    "df_user_reviews['posted'] = df_user_reviews['posted_new']\n",
    "df_user_reviews.drop('posted_new', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERAMOS COLUMNA YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrae el año de la columna 'posted' en df_user_reviews. Esta columna sera util para los endpoints\n",
    "df_user_reviews['year'] = df_user_reviews['posted'].str[:4]\n",
    "# Convertir la columna 'year' a tipo numérico\n",
    "df_user_reviews['year'] = pd.to_numeric(df_user_reviews['year'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECOMMEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews['recommend'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar los valores de True a 1 y False a 0 en la columna 'recommend'\n",
    "df_user_reviews['recommend'] = df_user_reviews['recommend'].astype(int)\n",
    "df_user_reviews['recommend'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volvemos a confirmar que no tenemos NULOS\n",
    "df_user_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ITEM-ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos a int\n",
    "df_user_reviews['item_id'] = df_user_reviews['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALISIS DE SENTIMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libreria Usada: Text Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews = pd.concat([df_user_reviews, sentimientoTextblob(df_user_reviews[\"review\"], \"sentiment_analysis\")], axis = 1)\n",
    "df_user_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de Reviews Negativas: \",df_user_reviews[df_user_reviews[\"sentiment_analysis\"] == 0].shape[0])\n",
    "print(\"Cantidad de Reviews Neutras  : \",df_user_reviews[df_user_reviews[\"sentiment_analysis\"] == 1].shape[0])\n",
    "print(\"Cantidad de Reviews Positivas: \",df_user_reviews[df_user_reviews[\"sentiment_analysis\"] == 2].shape[0])\n",
    "print(\"Cantidad TOTAL de Reviews    : \",df_user_reviews.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos a int\n",
    "df_user_reviews['sentiment_analysis'] = df_user_reviews['sentiment_analysis'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    " \n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRATAMIENTO DE USER ITEMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECCIONAMOS COLUMNAS RELEVANTES PARA EL MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_user_items = ['user_id', 'user_url', 'playtime_forever', 'item_id'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LECTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura previa al particionamiento\n",
    "#df_user_items_entero = leerJsonGz(\"Datos/\",\"users_items.json.gz\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura y union de particiones\n",
    "df_user_items = leerJsonGzPart(\"Datos/Particiones/\",\"users_items.json.gz\",1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se comprobo que el particionamiento ha funcionado correctamente\n",
    "#print(\"Shape Lectura Completa    : \", df_user_items_entero.shape)\n",
    "#print(\"Shape Lectura Particionada: \", df_user_items.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESANIDAMOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_items = desanidarJson(df_user_items, \"items\")\n",
    "df_user_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELIMINAMOS DUPLICADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_items.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos cantidad de Registros\n",
    "df_user_items.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_items.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos cantidad de Registros\n",
    "df_user_items.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLAYTIME 2 WEEKS y PLAYTIME FOREVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion a Numerico\n",
    "df_user_items[\"playtime_2weeks\"]  = pd.to_numeric(df_user_items[\"playtime_2weeks\"], errors='coerce')\n",
    "df_user_items[\"playtime_forever\"] = pd.to_numeric(df_user_items[\"playtime_forever\"], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos Nulos en playtime_2weeks\n",
    "df_user_items[df_user_items[\"playtime_2weeks\"].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos Nulos en playtime_forever\n",
    "df_user_items[df_user_items[\"playtime_forever\"].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos si los nulos se dan en ambas al mismo tiempo\n",
    "df_user_items[(df_user_items[\"playtime_2weeks\"].isna()) & (df_user_items[\"playtime_forever\"].isna())].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ambos estan en nulo, los pongo ambos en cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos la condicion\n",
    "ambos_nulos = (df_user_items[\"playtime_2weeks\"].isna()) & (df_user_items[\"playtime_forever\"].isna())\n",
    "# Actualizar los valores en las columnas 'playtime_2weeks' y 'playtime_forever' a 0.0\n",
    "df_user_items.loc[ambos_nulos, ['playtime_2weeks', 'playtime_forever']] = 0.0\n",
    "\n",
    "#Verificamos\n",
    "df_user_items[(df_user_items[\"playtime_2weeks\"].isna()) & (df_user_items[\"playtime_forever\"].isna())].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLAYTIME FOREVER = 0 & PLAYTIME 2 WEEKS != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reseteo indices\n",
    "df_user_items.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero cambiamos los tipos de datos de ambas\n",
    "df_user_items[\"playtime_forever\"] = df_user_items[\"playtime_forever\"].astype(float)\n",
    "df_user_items[\"playtime_2weeks\"]  = df_user_items[\"playtime_2weeks\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la condicion/mascara\n",
    "condicion = ((df_user_items[\"playtime_forever\"] == 0) & (df_user_items[\"playtime_2weeks\"] != 0))\n",
    "\n",
    "#Visualizamos algunos registros\n",
    "df_user_items[condicion].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantida de registros con PLAYTIME FOREVER = 0 & PLAYTIME 2 WEEKS != 0\n",
    "df_user_items[condicion].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asigno el valor de playtime_2weeks a playtime_forever\n",
    "# Asignar el valor de 'playtime_2weeks' a 'playtime_forever' en los registros que cumplen la condición\n",
    "df_user_items.loc[condicion, 'playtime_forever'] = df_user_items.loc[condicion, 'playtime_2weeks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantida de registros con PLAYTIME FOREVER = 0 & PLAYTIME 2 WEEKS != 0 POST imputaicon\n",
    "df_user_items.iloc[253243]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OTRAS TRANSFORMACIONES NECESARIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputamos -1 en item ID para los casos nulos\n",
    "df_user_items['item_id'].fillna(-1, inplace=True)\n",
    "#Convertimos a Int\n",
    "df_user_items['item_id'] = df_user_items['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERACION DE ARCHIVOS REDUCIDOS PARA C/ ENDPOINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) **<u> def userdata( User_id : str ):</u>**\n",
    "\n",
    "    Debe devolver cantidad de dinero gastado por el usuario, \n",
    "    el porcentaje de recomendación en base a reviews.recommend y \n",
    "    cantidad de items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREAREMOS 3 DFs REDUCIDOS (COMO SI FUESEN  VISTAS) para cada solicitud del ENDPOINT\n",
    "\n",
    "df_price_by_user\n",
    "\n",
    "df_perc_recommend_by_user\n",
    "\n",
    "df_cant_items_by_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usuarios Unicos\n",
    "df_user_items[\"user_id\"].unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>df_price_by_user:</u>**   Va a ser un DF agrupado por user_id con la sumatoria de todos los gastos (price) efectuados por ese usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos DF vacio\n",
    "df_spent_by_user = pd.DataFrame()\n",
    "\n",
    "#Agrego Columna de user_id\n",
    "df_spent_by_user[\"user_id\"] = df_user_items[\"user_id\"].unique()\n",
    "\n",
    "#verifico cantidad de registros\n",
    "df_spent_by_user.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DataFrame entre steam y users para tener el precio a nivel item_id\n",
    "df_merged_items_steam_by_itemid = df_user_items.merge(df_output_steam_json, on='item_id', how='left')\n",
    "#Por las dudas convertimos a float la columna precio\n",
    "df_merged_items_steam_by_itemid['price'] = df_merged_items_steam_by_itemid['price'].astype(float)\n",
    "\n",
    "df_merged_items_steam_by_itemid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total de Gastos/price (sum) por usuario\n",
    "df_spent_by_user = pd.merge(df_spent_by_user, df_merged_items_steam_by_itemid.groupby('user_id')['price'].sum().reset_index(), on='user_id', how='left')\n",
    "#Modificamos el nombre de la columna calculada\n",
    "df_spent_by_user.rename(columns={\"price\": \"spent\"}, inplace=True)\n",
    "#Visualizamos el df\n",
    "df_spent_by_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>df_perc_recommend_by_user:</u>**   Va a ser un DF agrupado por user_id el porcentaje de recomendaciones POSITIVAS(1) en funcion de las NEGATIVAS(0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DF vacio\n",
    "df_perc_recommend_by_user = pd.DataFrame()\n",
    "\n",
    "#Agrego Columna de user_id\n",
    "df_perc_recommend_by_user[\"user_id\"] = df_user_items[\"user_id\"].unique()\n",
    "\n",
    "#verifico cantidad de registros\n",
    "df_perc_recommend_by_user.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recomendaciones Negativas\n",
    "df_recommend_0 = df_user_reviews[df_user_reviews['recommend'] == 0].groupby('user_id')['recommend'].count().reset_index()\n",
    "df_recommend_0.rename(columns={\"recommend\": \"recommend_0\"}, inplace=True)\n",
    "#Recomendaciones positivas\n",
    "df_recommend_1 = df_user_reviews[df_user_reviews['recommend'] == 1].groupby('user_id')['recommend'].count().reset_index()\n",
    "df_recommend_1.rename(columns={\"recommend\": \"recommend_1\"}, inplace=True)\n",
    "\n",
    "#Combinamos ambos DFs\n",
    "df_recommend = pd.merge(df_recommend_0,df_recommend_1, on='user_id', how='inner')\n",
    "\n",
    "#Actuaslizamos los valores nulos\n",
    "df_recommend['recommend_0'].fillna(0, inplace=True)\n",
    "df_recommend['recommend_1'].fillna(0, inplace=True)\n",
    "\n",
    "# Convierte las columnas 'recommend_0' y 'recommend_1' a enteros\n",
    "df_recommend['recommend_0'] = df_recommend['recommend_0'].astype(int)\n",
    "df_recommend['recommend_1'] = df_recommend['recommend_1'].astype(int)\n",
    "\n",
    "\n",
    "#Calculamos el total de recomendaciones por usuario en una nueva columna, sumando las positivas y negativas\n",
    "df_recommend['recommend_total'] = df_recommend['recommend_0'] + df_recommend['recommend_1']\n",
    "df_recommend['recommend_total'] = df_recommend['recommend_total'].astype(int)\n",
    "\n",
    "\n",
    "#Calculamos el porcentaje con las columnas anteriores\n",
    "df_recommend['perc_recommend'] = 0  # Inicializa la columna con ceros\n",
    "df_recommend['perc_recommend'] = df_recommend['perc_recommend'].astype(float)\n",
    "\n",
    "nonzero_total_mask = df_recommend['recommend_total'] != 0 #Crea Mascara, porque sino podriamos generar una division por cero. \n",
    "df_recommend.loc[nonzero_total_mask, 'perc_recommend'] = (df_recommend['recommend_1'] / df_recommend['recommend_total']) * 100\n",
    "\n",
    "#Quitamos intermedias\n",
    "#df_recommend.drop(['recommend_0', 'recommend_1', 'recommend_total'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommend.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommend.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Juntamos con nuestro \"maestro\" de user_id el df anterior\n",
    "df_perc_recommend_by_user = pd.merge(df_perc_recommend_by_user,df_recommend, on='user_id', how='left')\n",
    "\n",
    "# Reemplaza los valores nulos por ceros \n",
    "df_perc_recommend_by_user['recommend_0'].fillna(0, inplace=True)\n",
    "df_perc_recommend_by_user['recommend_1'].fillna(0, inplace=True)\n",
    "df_perc_recommend_by_user['recommend_total'].fillna(0, inplace=True)\n",
    "df_perc_recommend_by_user['perc_recommend'].fillna(0, inplace=True)\n",
    "\n",
    "# Convierte el tipo de dato de la columna 'perc_recommend' a float\n",
    "df_perc_recommend_by_user['recommend_0'] = df_perc_recommend_by_user['recommend_0'].astype(float)\n",
    "df_perc_recommend_by_user['recommend_1'] = df_perc_recommend_by_user['recommend_1'].astype(float)\n",
    "df_perc_recommend_by_user['recommend_total'] = df_perc_recommend_by_user['recommend_total'].astype(float)\n",
    "df_perc_recommend_by_user['perc_recommend'] = df_perc_recommend_by_user['perc_recommend'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perc_recommend_by_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>df_cant_items_by_user:</u>**   Va a ser un DF agrupado por user_id Con la cantidad de items de cada user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DF vacio\n",
    "df_count_items_by_user = pd.DataFrame()\n",
    "\n",
    "#Agrego Columna de user_id\n",
    "df_count_items_by_user[\"user_id\"] = df_user_items[\"user_id\"].unique()\n",
    "\n",
    "#verifico cantidad de registros\n",
    "df_count_items_by_user.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregamos la columna de cantidad de items\n",
    "df_count_items_by_user = pd.merge(df_count_items_by_user, df_user_items.groupby('user_id')['item_id'].count().reset_index(), on='user_id', how='left')\n",
    "#Modificamos el nombre de la columna calculada\n",
    "df_count_items_by_user.rename(columns={\"item_id\": \"count_items\"}, inplace=True)\n",
    "# Reemplaza los valores nulos por ceros \n",
    "df_count_items_by_user['count_items'].fillna(0, inplace=True)\n",
    "# Convierte el tipo de dato de la columna 'perc_recommend' a float\n",
    "df_count_items_by_user['count_items'] = df_count_items_by_user['count_items'].astype(int)\n",
    "#Visualizamos el DF\n",
    "df_count_items_by_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPORTAMOS LOS 3 DFs EN formato JSON.GZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportamos los data frame\n",
    "grabarJsonGz(df_spent_by_user,'spent_by_user')\n",
    "grabarJsonGz(df_perc_recommend_by_user,'perc_recommend_by_user')\n",
    "grabarJsonGz(df_count_items_by_user,'count_items_by_user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) **<u>def countreviews( YYYY-MM-DD y YYYY-MM-DD : str ): </u>**\n",
    "\n",
    "    Cantidad de usuarios que realizaron reviews entre las fechas dadas y, \n",
    "    el porcentaje de recomendación de los mismos en base a reviews.recommend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREAREMOS 2 DFs REDUCIDOS (COMO SI FUESEN  VISTAS) para cada solicitud del ENDPOINT\n",
    "\n",
    "df_user_reviews_posted\n",
    "\n",
    "df_perc_recommend_by_user (creado para el Endo Point Anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews_posted = df_user_reviews[['user_id','item_id','posted','recommend']]\n",
    "df_user_reviews_posted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews_posted.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportamos los data frame\n",
    "grabarJsonGz(df_user_reviews_posted,'user_reviews_posted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) **<u>def genre ( género : str ):</u>**  \n",
    "\n",
    "    Devuelve el puesto en el que se encuentra un género sobre el ranking de los mismos analizado bajo la columna PlayTimeForever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_items[['item_id','playtime_forever']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar la cantidad máxima de géneros por 'item_id'\n",
    "max_genres_count = df_output_steam_json['genres'].str.count(',').max() + 1  # Agregar 1 para contar el primer género\n",
    "\n",
    "print(\"La cantidad máxima de géneros por 'item_id' es:\", max_genres_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json[df_output_steam_json['genres'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir la columna 'genres' en géneros individuales y crear un conjunto de géneros únicos\n",
    "unique_genres_set = set(df_output_steam_json['genres'].str.split(',').explode().str.strip())\n",
    "\n",
    "# Convertir el conjunto de géneros únicos en una lista\n",
    "unique_genres_list = list(unique_genres_set)\n",
    "\n",
    "# Mostrar la lista de géneros únicos\n",
    "print(unique_genres_list)\n",
    "print(len(unique_genres_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina filas con valores NaN en la columna 'item_id'\n",
    "df_user_items_tmp = df_user_items.dropna(subset=['item_id'])\n",
    "\n",
    "# Asegurarse de que la columna 'item_id' sea de tipo int64\n",
    "df_user_items_tmp.loc[:, 'item_id'] = df_user_items_tmp['item_id'].astype(int)\n",
    "\n",
    "# Paso 1: Dividir la columna 'genres' en géneros individuales\n",
    "df_genres_split = df_output_steam_json['genres'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).rename('genre').str.strip()\n",
    "\n",
    "# Paso 2: Unir los DataFrames utilizando 'item_id'\n",
    "df_merged = df_user_items_tmp.merge(df_genres_split, left_on='item_id', right_index=True)\n",
    "\n",
    "# Paso 3: Calcular el ranking de géneros en función de 'playtime_forever'\n",
    "genre_ranking = df_merged.groupby('genre')['playtime_forever'].sum().reset_index()\n",
    "\n",
    "# Ordenar el DataFrame en función del tiempo total de juego en orden descendente\n",
    "genre_ranking = genre_ranking.sort_values(by='playtime_forever', ascending=False)\n",
    "\n",
    "#Reseteamos indices\n",
    "genre_ranking.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Mostrar el ranking de géneros\n",
    "genre_ranking.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_ranking.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_ranking['genre'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DF vacio\n",
    "df_genre_ranking = pd.DataFrame()\n",
    "\n",
    "# Reiniciar el índice y agregar una nueva columna de ranking\n",
    "df_genre_ranking = genre_ranking[['genre']].reset_index(drop=True)\n",
    "\n",
    "# Renombrar la columna de ranking\n",
    "df_genre_ranking.rename(columns={'index': 'ranking'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportamos los data frame\n",
    "grabarJsonGz(df_genre_ranking,'genre_ranking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) **<u>def userforgenre ( género : str ):</u>**  \n",
    "\n",
    "    Top 5 de usuarios con más horas de juego en el género dado, con su URL (del user) y user_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir la columna genres en múltiples filas\n",
    "df_genres_split = df_output_steam_json['genres'].str.split(',').explode().str.strip()\n",
    "\n",
    "# Unir los DataFrames para obtener toda la información necesaria\n",
    "df_user_genre_ranking = df_user_items.merge(df_genres_split.to_frame(), left_on='item_id', right_index=True)\n",
    "\n",
    "#Seleccionamos columnas\n",
    "df_user_genre_ranking = df_user_genre_ranking.drop(columns=['items_count', 'steam_id', 'item_name', 'playtime_2weeks'])\n",
    "#Reordenamos las columnas\n",
    "df_user_genre_ranking = df_user_genre_ranking[['genres', 'user_id', 'item_id', 'playtime_forever', 'user_url']]\n",
    "\n",
    "#Visualizamos\n",
    "df_user_genre_ranking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportamos los data frame\n",
    "grabarJsonGz(df_user_genre_ranking,'user_genre_ranking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) **<u>def developer( desarrollador : str ): </u>**  \n",
    "\n",
    "    Cantidad de items y porcentaje de contenido Free por año según empresa desarrolladora. Ejemplo de salida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame con el nombre df_output_steam_tmp copiando df_output_steam_json\n",
    "df_output_steam_tmp = df_output_steam_json.copy()\n",
    "\n",
    "# Extraer el año de la columna 'release_date'\n",
    "df_output_steam_tmp['year'] = df_output_steam_tmp['release_date'].str[:4]\n",
    "\n",
    "# Convertir la columna 'year' a tipo numérico\n",
    "df_output_steam_tmp['year'] = pd.to_numeric(df_output_steam_tmp['year'], errors='coerce')\n",
    "\n",
    "# Filtrar los registros con año igual a 1900\n",
    "df_output_steam_tmp = df_output_steam_tmp[df_output_steam_tmp['year'] != 1900]\n",
    "\n",
    "# Calcular 'items_count' por desarrollador y año\n",
    "developer_items_count = df_output_steam_tmp.groupby(['developer', 'year'])['item_id'].count().reset_index()\n",
    "developer_items_count.rename(columns={'item_id': 'items_count'}, inplace=True)\n",
    "\n",
    "# Calcular 'free_content' por desarrollador y año\n",
    "developer_free_games = df_output_steam_tmp[df_output_steam_tmp['price'] == 0].groupby(['developer', 'year'])['item_id'].count().reset_index()\n",
    "developer_free_games.rename(columns={'item_id': 'free_count'}, inplace=True)\n",
    "\n",
    "# Combinar los DataFrames para calcular el porcentaje\n",
    "df_content_developer = developer_items_count.merge(developer_free_games, on=['developer', 'year'], how='left')\n",
    "df_content_developer['free_content'] = (df_content_developer['free_count'] / df_content_developer['items_count']) * 100\n",
    "df_content_developer.drop(columns=['free_count'], inplace=True)\n",
    "\n",
    "#Si no encuentra elementos con precio 0, ese registro va a quedar con Nan cuando deberia ser cero.\n",
    "df_content_developer['free_content'].fillna(0, inplace=True)\n",
    "\n",
    "# Visualizamos\n",
    "df_content_developer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportamos los data frame\n",
    "grabarJsonGz(df_content_developer,'content_developer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) **<u>def sentiment_analysis( año : int ): </u>**  \n",
    "\n",
    "    Según el año de lanzamiento, se devuelve una lista con la cantidad de registros de reseñas de usuarios que se encuentren categorizados con un análisis de sentimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el DataFrame df_review_year con la columna 'year'\n",
    "df_reviews_year = df_output_steam_json[['year']].drop_duplicates().copy()\n",
    "\n",
    "# Agrupa y suma los valores de sentiment_analysis en df_user_reviews por año\n",
    "sentiment_year = df_user_reviews.groupby(['year', 'sentiment_analysis'])['sentiment_analysis'].count().unstack(fill_value=0).reset_index()\n",
    "\n",
    "# Agregar las columnas 'Negativos', 'Neutros' y 'Positivos' en df_review_year\n",
    "df_reviews_year = df_reviews_year.merge(sentiment_year, on='year', how='left')\n",
    "\n",
    "# Cambiar los nombres de las columnas para mayor claridad\n",
    "df_reviews_year.rename(columns={0: 'Negativos', 1: 'Neutros', 2: 'Positivos'}, inplace=True)\n",
    "\n",
    "# Llenar NaN con 0 en las columnas 'Negativos', 'Neutros' y 'Positivos'\n",
    "df_reviews_year.fillna(0, inplace=True)\n",
    "\n",
    "# Convertir las columnas 'Negativos', 'Positivos' y 'Neutros' a enteros\n",
    "df_reviews_year['Negativos'] = df_reviews_year['Negativos'].astype(int)\n",
    "df_reviews_year['Positivos'] = df_reviews_year['Positivos'].astype(int)\n",
    "df_reviews_year['Neutros']   = df_reviews_year['Neutros'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_year.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_year.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_year[(df_reviews_year['Negativos'] != 0) | (df_reviews_year['Positivos'] != 0) | (df_reviews_year['Neutros'] != 0)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Años con reviews\n",
    "df_reviews_year[(df_reviews_year['Negativos'] != 0) | (df_reviews_year['Positivos'] != 0) | (df_reviews_year['Neutros'] != 0)]['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportamos los data frame\n",
    "grabarJsonGz(df_reviews_year,'reviews_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO DE RECOMENDACION ITEM-ITEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_steam_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARACION DE LOS DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAMOS A GENERAR UN ARCHIVO QUE SERA UTILIZADO COMO INPUT EN NUESTRO MODELO DE MACHINE LEARNING (RECOMENDACION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar columnas relevantes de cada conjunto de datos para el modelo de RECOMENDACION\n",
    "df_steam_recomendacion   = df_output_steam_json[['item_id', 'genres']]\n",
    "df_reviews_recomendacion = df_user_reviews[['user_id', 'item_id', 'sentiment_analysis']]\n",
    "#En este caso eliminamos los registros que teniamos sin item-id, a los cuales les imputamos -1\n",
    "df_items_recomendacion = df_user_items[df_user_items['item_id'] != -1][['user_id', 'item_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionar los datos en un solo conjunto\n",
    "merged_data = df_reviews_recomendacion.merge(df_items_recomendacion, on=['user_id', 'item_id'], how='inner')\n",
    "merged_data = merged_data.merge(df_steam_recomendacion, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir géneros en listas\n",
    "merged_data['genres'] = merged_data['genres'].apply(lambda x: x.split(', ') if isinstance(x, str) else [])\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar cuántos registros tienen listas vacías en la columna 'genres'\n",
    "registros_con_listas_vacias = merged_data[merged_data['genres'].apply(len) == 0]\n",
    "cantidad_registros_con_listas_vacias = len(registros_con_listas_vacias)\n",
    "\n",
    "print(\"Cantidad de registros con listas vacías en la columna 'genres':\", cantidad_registros_con_listas_vacias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar registros con listas vacías en la columna 'genres'\n",
    "merged_data = merged_data[merged_data['genres'].apply(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATRIZ DE CARACTERISTICAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar registros con 'genres' vacíos o NaN\n",
    "merged_data = merged_data.dropna(subset=['genres'])\n",
    "merged_data = merged_data[merged_data['genres'].astype(bool)]\n",
    "\n",
    "# Calcular la moda de sentimiento (sentiment_analysis) para cada juego\n",
    "mode_sentiment = merged_data.groupby('item_id')['sentiment_analysis'].agg(lambda x: statistics.mode(x) if len(x) > 0 else None).reset_index()\n",
    "mode_sentiment.rename(columns={'sentiment_analysis': 'mode_sentiment'}, inplace=True)\n",
    "\n",
    "# Utilizar la función explode para descomponer la lista de géneros en filas separadas\n",
    "genres_expanded = merged_data.explode('genres')\n",
    "\n",
    "# Codificar géneros como variables dummy (one-hot encoding)\n",
    "genres_dummy = pd.get_dummies(genres_expanded['genres'], prefix='genre')\n",
    "\n",
    "# Combinar géneros dummy por 'item_id' utilizando sum()\n",
    "genres_dummy = genres_dummy.groupby(genres_expanded['item_id']).sum()\n",
    "\n",
    "# Reiniciar el índice\n",
    "genres_dummy.reset_index(inplace=True)\n",
    "\n",
    "# Combinar moda y dummies \n",
    "features = mode_sentiment.merge(genres_dummy, on='item_id', how='left')\n",
    "\n",
    "# Mostrar una muestra del conjunto de datos fusionado con la moda de sentimiento y codificación one-hot de géneros\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llenar valores NaN con 0 en el conjunto de datos 'features'\n",
    "features.fillna(0, inplace=True)\n",
    "\n",
    "# Calcular la matriz de similitud del coseno\n",
    "similarities = cosine_similarity(features.drop(columns=['item_id']))\n",
    "\n",
    "# Crear un DataFrame con la matriz de similitud\n",
    "df_similarities = pd.DataFrame(similarities, index=features['item_id'], columns=features['item_id'])\n",
    "\n",
    "# Mostrar una muestra de la matriz de similitud\n",
    "print(df_similarities.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similarities.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LA TABLA ES UN POCO GRANDE, CON LO CUAL VAMOS A APLICAR ALGUNA TECNICA PARA REDUCIR EL ESPACIO.\n",
    "\n",
    "SABEMOS QUE MI API SOLO RECOMENDARA 5 JUEGOS SIMILARES, ENTONCES NO ME INTERESA GUARDAR MAS DE 5 ITEMs SIMILARES POR CADA ITEM. ESTO REDUCIRIA CONSIDERABLEMENTE EL ESPACIO OCUPADA POR EL ARCHIVO/TABLA/DF. ADEMAS, LA RESPUESTA DE LA API SERIA MUCHO MAS RAPIDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similarities.index = df_similarities.index.astype(int)\n",
    "recommendations_dict = {}\n",
    "\n",
    "for item_id, row in df_similarities.iterrows():\n",
    "    item_id = int(item_id)\n",
    "    similar_games = df_similarities.loc[item_id].sort_values(ascending=False)\n",
    "    similar_games.index = similar_games.index.astype(int)\n",
    "    top_similar_games = similar_games[similar_games.index != item_id].index[:5]        \n",
    "    # Almacenar las recomendaciones en el diccionario\n",
    "    recommendations_dict[item_id] = top_similar_games.tolist()\n",
    "\n",
    "\n",
    "# Convertir el diccionario en un nuevo DataFrame\n",
    "df_reduced_recommendations = pd.DataFrame.from_dict(recommendations_dict, orient='index')\n",
    "\n",
    "# Asignar nombres a las columnas\n",
    "df_reduced_recommendations.columns = ['recommend_1', 'recommend_2', 'recommend_3', 'recommend_4', 'recommend_5']\n",
    "\n",
    "# Asegurarse de que el índice sea 'item_id'\n",
    "df_reduced_recommendations.index.name = 'item_id'\n",
    "df_reduced_recommendations.index = df_reduced_recommendations.index.astype(int)\n",
    "\n",
    "df_reduced_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mover el índice a una columna llamada 'item_id' y restablecer el índice\n",
    "df_reduced_recommendations['item_id'] = df_reduced_recommendations.index\n",
    "df_reduced_recommendations.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Exportamos la matriz de caracteristicas para poder consumirla en la API\n",
    "grabarJsonGz(df_reduced_recommendations,'df_recommendations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERAREMOS UN ARCHIVO CON EL RANKING DE JUEGOS EN FUNCION A LA CANTIDAD DE REVIEWS POSITIVAS QUE SE DETECTARON EN EL ANALISIS DE SENTIMIENTO. DE ESA LISTA DEVOLVEREMOS SOLO EL TOP5.\n",
    "\n",
    "UTILIZAREMOS ESTA LISTA PARA DEVOLVER EN CASO QUE EL ITEM ID INGRESADO EN LA API NO ESTE EN NUESTRO ARCHIVO DE RECOMENDACIONES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar las filas donde sentiment_analysis es igual a 2\n",
    "positive_reviews = df_user_reviews[df_user_reviews['sentiment_analysis'] == 2]\n",
    "\n",
    "# Calcular el recuento de reviews positivas por item_id\n",
    "positive_reviews_count = positive_reviews.groupby('item_id')['sentiment_analysis'].count().reset_index()\n",
    "\n",
    "# Renombrar la columna de recuento\n",
    "positive_reviews_count.columns = ['item_id', 'positive_reviews_count']\n",
    "\n",
    "# Ordenar el DataFrame por la columna 'positive_reviews_count' en orden descendente y tomar los primeros 5 registros\n",
    "top_5_games = positive_reviews_count.sort_values(by='positive_reviews_count', ascending=False).head(5)\n",
    "\n",
    "# Seleccionar solo la columna 'item_id'\n",
    "top_5_item_ids = top_5_games['item_id']\n",
    "\n",
    "# Crear un nuevo DataFrame solo con la columna 'item_id'\n",
    "df_default_recommend_5 = pd.DataFrame({'item_id': top_5_item_ids})\n",
    "\n",
    "#Casteamos el item_id por las dudas\n",
    "df_default_recommend_5['item_id'] = df_default_recommend_5['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportamos\n",
    "grabarJsonGz(df_default_recommend_5,'default_recommend_5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
